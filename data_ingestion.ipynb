{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6f20eff-13e9-454a-be32-0b4215c41eb4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install dependencies"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt --force-reinstall\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32c748c4-b3ff-4d96-be84-3ac9fa840f97",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Parameters"
    }
   },
   "outputs": [],
   "source": [
    "# Widgets for easy evaluator input\n",
    "dbutils.widgets.text(\"input_question\", \"Summarize the following legal case\")\n",
    "dbutils.widgets.text(\"embedding_endpoint\", \"databricks-bge-large-en\")\n",
    "dbutils.widgets.text(\"llm_endpoint\", \"databricks-meta-llama-3-1-8b-instruct\")\n",
    "dbutils.widgets.text(\"k\", \"3\")  # number of retrieved chunks\n",
    "\n",
    "# Retrieve widget values\n",
    "input_question = dbutils.widgets.get(\"input_question\")\n",
    "embedding_endpoint = dbutils.widgets.get(\"embedding_endpoint\")\n",
    "llm_endpoint = dbutils.widgets.get(\"llm_endpoint\")\n",
    "k = int(dbutils.widgets.get(\"k\"))\n",
    "\n",
    "print(f\"ðŸ“Œ Parameters set:\\n- Question: {input_question}\\n- Chunks: {k}\\n- Embedding: {embedding_endpoint}\\n- LLM: {llm_endpoint}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9af8782-591b-4e90-bff3-4da3d4740541",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fetch and Load Data"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ChicagoHAI/CaseSumm\")\n",
    "\n",
    "# Convert the 'train' split to Pandas\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# Select required columns and rename\n",
    "df = df[['opinion', 'syllabus']].rename(columns={\n",
    "    'opinion': 'text',\n",
    "    'syllabus': 'summary'\n",
    "})\n",
    "\n",
    "spark_df = spark.createDataFrame(df)\n",
    "\n",
    "spark_df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"legal.bronze.casesumm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4a386a7-c488-4afb-8bff-4458452270ad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Chunk and Embed Documents"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import DatabricksEmbeddings\n",
    "import os\n",
    "\n",
    "# --- Config ---\n",
    "TABLE_NAME = \"legal.bronze.casesumm\"\n",
    "BATCH_SIZE = 5000  # number of rows per batch (tune for serverless memory)\n",
    "FAISS_DIR = \"/Volumes/legal/bronze/casesumm_volume/casesumm_faiss\"\n",
    "\n",
    "# --- Setup ---\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=150)\n",
    "embeddings = DatabricksEmbeddings(endpoint=embedding_endpoint)\n",
    "\n",
    "# Prepare an empty FAISS index for merging\n",
    "main_vectorstore = None\n",
    "\n",
    "# --- Process in batches ---\n",
    "batch_num = 0\n",
    "batch_texts = []\n",
    "print(\"Starting processing\")\n",
    "for row in (\n",
    "    spark.table(TABLE_NAME)\n",
    "    .select(\"text\")\n",
    "    .where(\"text IS NOT NULL\")\n",
    "    .limit(5000)\n",
    "    .toLocalIterator()  # stream to driver row-by-row\n",
    "):\n",
    "    \n",
    "    batch_texts.append(row[\"text\"])  # row is a Row, access the column value\n",
    "\n",
    "    if len(batch_texts) >= BATCH_SIZE:\n",
    "        # Process this batch\n",
    "        docs = splitter.create_documents(batch_texts)\n",
    "        vs = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "        if main_vectorstore is None:\n",
    "            main_vectorstore = vs\n",
    "        else:\n",
    "            main_vectorstore.merge_from(vs)\n",
    "\n",
    "        batch_texts = []\n",
    "        batch_num += 1\n",
    "        print(f\"Processed batch {batch_num}\")\n",
    "\n",
    "# Process any leftover texts        \n",
    "if batch_texts:\n",
    "    docs = splitter.create_documents(batch_texts)\n",
    "    print(f\"Total chunks created: {len(docs)}\")\n",
    "    vs = FAISS.from_documents(docs, embeddings)\n",
    "    if main_vectorstore is None:\n",
    "        main_vectorstore = vs\n",
    "    else:\n",
    "        main_vectorstore.merge_from(vs)\n",
    "\n",
    "# --- Save final FAISS index ---\n",
    "os.makedirs(FAISS_DIR, exist_ok=True)\n",
    "main_vectorstore.save_local(FAISS_DIR)\n",
    "print(f\"âœ… FAISS index saved to {FAISS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8e50ef0-b301-4231-8b3f-43fe6b4fc5f5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Build the RAG Pipeline"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import DatabricksEmbeddings\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "\n",
    "# config - change these to your values\n",
    "FAISS_DIR = \"/Volumes/legal/bronze/casesumm_volume/casesumm_faiss\"\n",
    "\n",
    "# create embeddings wrapper (used for loading the FAISS index)\n",
    "embeddings = DatabricksEmbeddings(endpoint=embedding_endpoint)\n",
    "\n",
    "# load the saved FAISS index\n",
    "vectorstore = FAISS.load_local(FAISS_DIR, embeddings, allow_dangerous_deserialization=True)\n",
    "print(\"Loaded FAISS with\", vectorstore.index.ntotal, \"vectors (if available).\")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "llm = ChatDatabricks(\n",
    "    endpoint=llm_endpoint,\n",
    "    temperature=0.1,\n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "def rag_pipeline(case_text: str) -> str:\n",
    "    # Retrieve relevant chunks\n",
    "    docs = retriever.invoke(case_text)\n",
    "\n",
    "    # Combine into a single context\n",
    "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "    # Prompt for summarization\n",
    "    prompt = f\"\"\"\n",
    "    You are a legal assistant. Write in 4â€“5 sentences covering the main legal arguments and conclusion:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Summary:\n",
    "    \"\"\"\n",
    "\n",
    "    # Call LLM\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15799f37-e27c-4236-8fa9-0f1af2d23480",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Q&A system"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "DEFAULT_K = 3\n",
    "def legal_qa(query: str, top_k: int = DEFAULT_K) -> tuple[str, list]:\n",
    "    # similarity_search returns Documents with page_content and metadata\n",
    "    docs = vectorstore.similarity_search(query, k=top_k)\n",
    "\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    # Construct prompt for LLM\n",
    "    prompt = f\"\"\"\n",
    "    You are a knowledgeable legal expert assistant. Use the following context excerpts from legal cases to answer the question below concisely and accurately.\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Question:\n",
    "    {query}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    # Generate answer from LLM\n",
    "    response = llm.invoke(prompt)\n",
    "    answer = response.content if hasattr(response, \"content\") else str(response)\n",
    "\n",
    "    return answer, docs\n",
    "\n",
    "# Example\n",
    "q = input_question\n",
    "answer, source_chunks = legal_qa(q, top_k=k)\n",
    "\n",
    "print(\"=== Answer ===\")\n",
    "print(answer)\n",
    "\n",
    "print(\"\\n=== Source Chunks ===\")\n",
    "for i, chunk in enumerate(source_chunks, 1):\n",
    "    print(f\"[Chunk {i}] {chunk.page_content[:500].replace(chr(10), ' ')}...\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3f21330-65a7-47e3-829c-f42cdf806316",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Load table from Unity Catalog\n",
    "df = spark.table(\"legal.bronze.casesumm\").limit(1)\n",
    "case = df.collect()[0]\n",
    "\n",
    "case_text = case[\"text\"]\n",
    "ground_truth_summary = case[\"summary\"]\n",
    "\n",
    "print(\"Case text length:\", len(case_text))\n",
    "print(\"Ground truth summary:\", ground_truth_summary[:200], \"...\")\n",
    "\n",
    "generated_summary = rag_pipeline(case_text)\n",
    "print(\"Generated Summary:\", generated_summary[:200], \"...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c7825f9-78c1-4fe6-82cc-771d538f11c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45c5328f-dfec-447a-bd47-c0d8b86e6b7e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Evaluate the LLM Output"
    }
   },
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(ground_truth_summary, generated_summary)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for metric, score in scores.items():\n",
    "    rows.append({\n",
    "        \"Metric\": metric.upper(),\n",
    "        \"Precision\": score.precision,\n",
    "        \"Recall\": score.recall,\n",
    "        \"F1\": score.fmeasure\n",
    "    })\n",
    "\n",
    "df_scores = pd.DataFrame(rows)\n",
    "\n",
    "display(df_scores)\n",
    "\n",
    "# Chart\n",
    "plt.figure(figsize=(8,5))\n",
    "for col in [\"Precision\", \"Recall\", \"F1\"]:\n",
    "    plt.plot(df_scores[\"Metric\"], df_scores[col], marker='o', label=col)\n",
    "\n",
    "plt.title(\"ROUGE Scores\")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# df_scores\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5535544594287156,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "data_ingestion",
   "widgets": {
    "embedding_endpoint": {
     "currentValue": "databricks-bge-small-en",
     "nuid": "d8165ac1-4ae1-476c-950a-c8695057441d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "databricks-bge-large-en",
      "label": null,
      "name": "embedding_endpoint",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "databricks-bge-large-en",
      "label": null,
      "name": "embedding_endpoint",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "input_question": {
     "currentValue": "what is mentioned about the Interstate Commerce Commission to the Federal Communications Commission?",
     "nuid": "6373f260-719e-4f8a-b29a-d1e7e5e08d00",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "Summarize the following legal case",
      "label": null,
      "name": "input_question",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "Summarize the following legal case",
      "label": null,
      "name": "input_question",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "k": {
     "currentValue": "3",
     "nuid": "e5d94f42-60e8-4333-8e11-dc0f9d813d68",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "3",
      "label": null,
      "name": "k",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "3",
      "label": null,
      "name": "k",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "k_val": {
     "currentValue": "5",
     "nuid": "5e0084c8-fa1e-4a5d-9625-b1af5b678bc1",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "5",
      "label": null,
      "name": "k_val",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "5",
      "label": null,
      "name": "k_val",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "llm_endpoint": {
     "currentValue": "databricks-meta-llama-3-1-8b-instruct",
     "nuid": "3d02d42a-6a36-4de4-a430-5750ccfee5a8",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "databricks-meta-llama-3-1-8b-instruct",
      "label": null,
      "name": "llm_endpoint",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "databricks-meta-llama-3-1-8b-instruct",
      "label": null,
      "name": "llm_endpoint",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
