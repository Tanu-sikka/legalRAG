{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6f20eff-13e9-454a-be32-0b4215c41eb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt --force-reinstall\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32c748c4-b3ff-4d96-be84-3ac9fa840f97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Widgets for easy evaluator input\n",
    "dbutils.widgets.text(\"input_question\", \"Summarize the following legal case\")\n",
    "dbutils.widgets.text(\"embedding_endpoint\", \"databricks-bge-large-en\")\n",
    "dbutils.widgets.text(\"llm_endpoint\", \"databricks-meta-llama-3-1-8b-instruct\")\n",
    "dbutils.widgets.text(\"k\", \"5\")  # number of retrieved chunks\n",
    "\n",
    "# Retrieve widget values\n",
    "input_question = dbutils.widgets.get(\"input_question\")\n",
    "embedding_endpoint = dbutils.widgets.get(\"embedding_endpoint\")\n",
    "llm_endpoint = dbutils.widgets.get(\"llm_endpoint\")\n",
    "k_val = int(dbutils.widgets.get(\"k\"))\n",
    "\n",
    "print(f\"ðŸ“Œ Parameters set:\\n- Question: {input_question}\\n- Chunks: {k_val}\\n- Embedding: {embedding_endpoint}\\n- LLM: {llm_endpoint}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f2e7b8e-243e-499a-9802-84b629dec9ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "print(np.__version__)\n",
    "print(faiss.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9af8782-591b-4e90-bff3-4da3d4740541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "cache_path = \"/Volumes/legal/bronze/casesumm_volume/huggingface_cache\"\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = cache_path\n",
    "\n",
    "dataset = load_dataset(\"ChicagoHAI/CaseSumm\", cache_dir=cache_path)\n",
    "\n",
    "# Convert the 'train' split to Pandas\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# Select required columns and rename\n",
    "df = df[['opinion', 'syllabus']].rename(columns={\n",
    "    'opinion': 'text',\n",
    "    'syllabus': 'summary'\n",
    "})\n",
    "\n",
    "spark_df = spark.createDataFrame(df)\n",
    "\n",
    "spark_df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"legal.bronze.casesumm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32e4d3ac-eb6b-4706-a175-61e15e53261d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from legal.bronze.casesumm limit 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4a386a7-c488-4afb-8bff-4458452270ad",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Indexing"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import DatabricksEmbeddings\n",
    "import os\n",
    "\n",
    "# --- Config ---\n",
    "TABLE_NAME = \"legal.bronze.casesumm\"\n",
    "BATCH_SIZE = 5000  # number of rows per batch (tune for serverless memory)\n",
    "FAISS_DIR = \"/Volumes/legal/bronze/casesumm_volume/casesumm_faiss\"\n",
    "\n",
    "# --- Setup ---\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=150)\n",
    "embeddings = DatabricksEmbeddings(endpoint=embedding_endpoint)\n",
    "\n",
    "# Prepare an empty FAISS index for merging\n",
    "main_vectorstore = None\n",
    "\n",
    "# --- Process in batches ---\n",
    "batch_num = 0\n",
    "for batch_df in (\n",
    "    spark.table(TABLE_NAME)\n",
    "    .select(\"text\")\n",
    "    .where(\"text IS NOT NULL\")\n",
    "    .limit(1000000)  # optional: safety limit during first run\n",
    "    .toLocalIterator()  # stream to driver row-by-row\n",
    "):\n",
    "    batch_texts = []\n",
    "    for row in batch_df:\n",
    "        batch_texts.append(row)\n",
    "        if len(batch_texts) >= BATCH_SIZE:\n",
    "            # Process this batch\n",
    "            docs = splitter.create_documents(batch_texts)\n",
    "            vs = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "            if main_vectorstore is None:\n",
    "                main_vectorstore = vs\n",
    "            else:\n",
    "                main_vectorstore.merge_from(vs)\n",
    "\n",
    "            batch_texts = []\n",
    "            batch_num += 1\n",
    "            print(f\"Processed batch {batch_num}\")\n",
    "\n",
    "# Process any leftover texts\n",
    "if batch_texts:\n",
    "    docs = splitter.create_documents(batch_texts)\n",
    "    vs = FAISS.from_documents(docs, embeddings)\n",
    "    if main_vectorstore is None:\n",
    "        main_vectorstore = vs\n",
    "    else:\n",
    "        main_vectorstore.merge_from(vs)\n",
    "\n",
    "# --- Save final FAISS index ---\n",
    "os.makedirs(FAISS_DIR, exist_ok=True)\n",
    "main_vectorstore.save_local(FAISS_DIR)\n",
    "print(f\"âœ… FAISS index saved to {FAISS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15799f37-e27c-4236-8fa9-0f1af2d23480",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def retrieve_top_k(query: str, k: int = k_val):\n",
    "    # similarity_search returns Documents with page_content and metadata\n",
    "    docs = vectorstore.similarity_search(query, k=k)\n",
    "    return docs\n",
    "\n",
    "# Example\n",
    "q = input_question\n",
    "top_docs = retrieve_top_k(q, k=k_val)\n",
    "for i, d in enumerate(top_docs, 1):\n",
    "    print(f\"--- chunk #{i} ---\")\n",
    "    print(d.page_content[:500].replace(\"\\n\", \" \"))  # print first 500 chars\n",
    "    print(\"metadata:\", d.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8e50ef0-b301-4231-8b3f-43fe6b4fc5f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import DatabricksEmbeddings\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "\n",
    "# config - change these to your values\n",
    "FAISS_DIR = \"/Volumes/legal/bronze/casesumm_volume/casesumm_faiss\"\n",
    "\n",
    "# create embeddings wrapper (used for loading the FAISS index)\n",
    "embeddings = DatabricksEmbeddings(endpoint=embedding_endpoint)\n",
    "\n",
    "# load the saved FAISS index\n",
    "vectorstore = FAISS.load_local(FAISS_DIR, embeddings, allow_dangerous_deserialization=True)\n",
    "print(\"Loaded FAISS with\", vectorstore.index.ntotal, \"vectors (if available).\")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "llm = ChatDatabricks(\n",
    "    endpoint=llm_endpoint,\n",
    "    temperature=0.0,\n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "def rag_pipeline(case_text: str) -> str:\n",
    "    # Retrieve relevant chunks\n",
    "    docs = retriever.get_relevant_documents(case_text)\n",
    "\n",
    "    # Combine into a single context\n",
    "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "    # Prompt for summarization\n",
    "    prompt = f\"\"\"\n",
    "    You are a legal assistant. Write in 4â€“5 sentences covering the main legal arguments and conclusion:\n",
    "\n",
    "    {context}\n",
    "\n",
    "    Summary:\n",
    "    \"\"\"\n",
    "\n",
    "    # Call LLM\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3f21330-65a7-47e3-829c-f42cdf806316",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Load table from Unity Catalog\n",
    "df = spark.table(\"legal.bronze.casesumm\").limit(1)\n",
    "case = df.collect()[0]\n",
    "\n",
    "case_text = case[\"text\"]\n",
    "ground_truth_summary = case[\"summary\"]\n",
    "\n",
    "print(\"Case text length:\", len(case_text))\n",
    "print(\"Ground truth summary:\", ground_truth_summary[:200], \"...\")\n",
    "\n",
    "generated_summary = rag_pipeline(case_text)\n",
    "print(\"Generated Summary:\", generated_summary[:200], \"...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c7825f9-78c1-4fe6-82cc-771d538f11c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45c5328f-dfec-447a-bd47-c0d8b86e6b7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "scores = scorer.score(ground_truth_summary, generated_summary)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for metric, score in scores.items():\n",
    "    rows.append({\n",
    "        \"Metric\": metric.upper(),\n",
    "        \"Precision\": score.precision,\n",
    "        \"Recall\": score.recall,\n",
    "        \"F1\": score.fmeasure\n",
    "    })\n",
    "\n",
    "df_scores = pd.DataFrame(rows)\n",
    "df_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bf9401d-adf3-4ec2-8485-afa529757e2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Table display (Databricks automatically renders Pandas DataFrames nicely)\n",
    "display(df_scores)\n",
    "\n",
    "# Chart\n",
    "plt.figure(figsize=(8,5))\n",
    "for col in [\"Precision\", \"Recall\", \"F1\"]:\n",
    "    plt.plot(df_scores[\"Metric\"], df_scores[col], marker='o', label=col)\n",
    "\n",
    "plt.title(\"ROUGE Scores\")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5535544594287156,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "data_ingestion",
   "widgets": {
    "embedding_endpoint": {
     "currentValue": "databricks-bge-large-en",
     "nuid": "d8165ac1-4ae1-476c-950a-c8695057441d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "databricks-bge-large-en",
      "label": null,
      "name": "embedding_endpoint",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "databricks-bge-large-en",
      "label": null,
      "name": "embedding_endpoint",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "input_question": {
     "currentValue": "give me your views on the case",
     "nuid": "6373f260-719e-4f8a-b29a-d1e7e5e08d00",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "Summarize the following legal case",
      "label": null,
      "name": "input_question",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "Summarize the following legal case",
      "label": null,
      "name": "input_question",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "k": {
     "currentValue": "5",
     "nuid": "e5d94f42-60e8-4333-8e11-dc0f9d813d68",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "5",
      "label": null,
      "name": "k",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "5",
      "label": null,
      "name": "k",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "k_val": {
     "currentValue": "5",
     "nuid": "5e0084c8-fa1e-4a5d-9625-b1af5b678bc1",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "5",
      "label": null,
      "name": "k_val",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "5",
      "label": null,
      "name": "k_val",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "llm_endpoint": {
     "currentValue": "databricks-meta-llama-3-1-8b-instruct",
     "nuid": "3d02d42a-6a36-4de4-a430-5750ccfee5a8",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "databricks-meta-llama-3-1-8b-instruct",
      "label": null,
      "name": "llm_endpoint",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "databricks-meta-llama-3-1-8b-instruct",
      "label": null,
      "name": "llm_endpoint",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
